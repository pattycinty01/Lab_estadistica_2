knitr::include_graphics("logoPUCP.png")
library(twitteR) #  para conectarse a la API
library(twitteR) #  para conectarse a la API
library(rtweet) # para descargar los tweets
library(rio)
library(lubridate)
library(tidyverse)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(base64enc)
library(wordcloud)
library(SentimentAnalysis)
knitr::include_graphics("token.png")
api_key <- "INo8S26V2ioq1paffd6XxR3AK"
api_secret <- "fMZdzsmoGev5y45eiqdIFZiKL9uf1NjXxDADvfzLFlFQdASSvv"
access_token <- "310046080-xVRRUdiOMTqMdnbNmdUll0I152xVhPRuDSllXd8v"
access_token_secret <- "HLtDM1O1bU6ieHhpoebmxe36Ia55hcci7tsk2sc9OWy0a"
token<- create_token(app = "App2Xzy", api_key, api_secret,access_token, access_token_secret)
cerron <- get_timeline("@VLADIMIR_CERRON", 1000)
cerron[1,5]
cerron <- get_timeline("@MinCulturaPe", 1000)
cerron[1,5]
api_key <- "INo8S26V2ioq1paffd6XxR3AK"
api_secret <- "fMZdzsmoGev5y45eiqdIFZiKL9uf1NjXxDADvfzLFlFQdASSvv"
access_token <- "310046080-xVRRUdiOMTqMdnbNmdUll0I152xVhPRuDSllXd8v"
access_token_secret <- "HLtDM1O1bU6ieHhpoebmxe36Ia55hcci7tsk2sc9OWy0a"
token<- create_token(app = "App2Xzy", api_key, api_secret,access_token, access_token_secret)
cerron <- get_timeline("@MinCulturaPe", 1000)
cerron[1,5]
api_key <- "35FVibXbAwPZfJrd9hqvQgETt"
api_secret <- "fSm8xWZrKhwnpp6MdpVfqzksOLAPoymFb45bW7W7PuIKamMQoI"
access_token <- "226242119-iMt7C53QNLGK59PfRHA3C8luAEr5BAWmeVuoJQLf"
access_token_secret <- "hm2FWw1URVsGKM9DBgXVxrTQuU8A29A5sSJ2j8pKlxkGJ"
token<- create_token(app = "App2Xzy", api_key, api_secret,access_token, access_token_secret)
token<- create_token(app = "App2Xzy", api_key, api_secret,access_token, access_token_secret)
cerron <- get_timeline("@MinCulturaPe", 1000)
cerron[1,5]
View(cerron)
knitr::include_graphics("twt.png")
knitr::include_graphics("twt2.png")
api_key = "pGHpp2MRBfbw07UXs8DCZPP70"
api_secret = "V6iO16LosRZ4sLVz2FsSwi1XFOjJY5Ve01gSR6ioP6rsscM2oM"
access_token = "226242119-A3MmuRlsWEpMPEnhepelb4yo3hwDK90JsYKagZsq"
access_token_secret = "rAITgpvcls6lrBSyKPZ9TAdPXJYML3qq3QmEToe0VTfOq"
?create_token
token<- create_token(app = "GRT1APP", api_key, api_secret,access_token, access_token_secret)
?get_timeline
View(cerron)
mc_twt <- get_timeline("@MinCulturaPe", since_id = 2023)
View(cerron)
mc_twt <- get_timeline("@MinCulturaPe", 2000)
mc_twt <- get_timeline("@MinCulturaPe", 1000)
api_key = "pGHpp2MRBfbw07UXs8DCZPP70"
api_secret = "V6iO16LosRZ4sLVz2FsSwi1XFOjJY5Ve01gSR6ioP6rsscM2oM"
access_token = "226242119-A3MmuRlsWEpMPEnhepelb4yo3hwDK90JsYKagZsq"
access_token_secret = "rAITgpvcls6lrBSyKPZ9TAdPXJYML3qq3QmEToe0VTfOq"
library(twitteR)
token<- create_token(app = "GRT1APP", api_key, api_secret,access_token, access_token_secret)
library(rtweet)
mc_twt <- get_timeline("@MinCulturaPe", 1000)
api_key <- "35FVibXbAwPZfJrd9hqvQgETt"
api_secret <- "fSm8xWZrKhwnpp6MdpVfqzksOLAPoymFb45bW7W7PuIKamMQoI"
access_token <- "226242119-iMt7C53QNLGK59PfRHA3C8luAEr5BAWmeVuoJQLf"
access_token_secret <- "hm2FWw1URVsGKM9DBgXVxrTQuU8A29A5sSJ2j8pKlxkGJ"
token<- create_token(app = "App2Xzy", api_key, api_secret,access_token, access_token_secret)
cerron <- get_timeline("@MinCulturaPe", 1000)
cerron[1,5]
api_key = "FTIcvj7g6Y1mC5Y1OzEh3JZuJ"
api_secret = "Q2qNZKVW2mFo0uGiAlfu1pUpSPJWJOu7QMHpIXRNVOoTZp2tQ7"
access_token = "226242119-hIEVpAn1WguJucKsZ9Gpm25wLvh8aPUQltUiehf6"
access_token_secret = "pwlLdmZyeE0kDXYiwDNelC82pCksEgTyGruDHUIoHC220"
library(twitteR)
token<- create_token(app = "GRT1APP", api_key, api_secret,access_token, access_token_secret)
library(rtweet)
mc_twt <- get_timeline("@MinCulturaPe", 1000)
api_key = "FTIcvj7g6Y1mC5Y1OzEh3JZuJ"
api_secret = "Q2qNZKVW2mFo0uGiAlfu1pUpSPJWJOu7QMHpIXRNVOoTZp2tQ7"
access_token = "226242119-hIEVpAn1WguJucKsZ9Gpm25wLvh8aPUQltUiehf6"
access_token_secret = "pwlLdmZyeE0kDXYiwDNelC82pCksEgTyGruDHUIoHC220"
library(twitteR)
token<- create_token(app = "GRT1APP", api_key, api_secret,access_token, access_token_secret)
library(twitteR)
token<- create_token(app = "GRT1APP", api_key, api_secret,access_token, access_token_secret)
library(rtweet)
mc_twt <- get_timeline("@MinCulturaPe", 1000)
mc_twt = get_timeline("@MinCulturaPe", 50)
library(htmltab)
install.packages("htmltab")
library(htmltab)
library(htmltab)
library(htmltab)
library(rvest)
url="https://www.gob.pe/institucion/rree/funcionarios"
pagina_web=read_html(url)
css_nombre="h3.text-2xl" # contenemos la clase CSS en un objeto
nombre_html <- html_nodes(pagina_web,css_nombre) # con html_nodes y html_text, obtenemos el código html que contiene los nombres
nombre_texto <- html_text(nombre_html)
head(nombre_texto) #vemos los datos
css_cargo="p"
cargo_html <- html_nodes(pagina_web,css_cargo)
cargo_texto <- html_text(cargo_html)
head(cargo_texto)
dataWS3 <- data.frame(NOMBRE = nombre_texto, CARGO = cargo_texto)
head(dataWS3)
url="https://www.congreso.gob.pe/?K=113"
pagina_web=read_html(url)
css_nombre="a.conginfo" # contenemos la clase CSS en un objeto
nombre_html <- html_nodes(pagina_web,css_nombre) # con html_nodes y html_text, obtenemos el código html que contiene los países
nombre_texto <- html_text(nombre_html)
head(nombre_texto) #vemos los datos
css_grupo="span.partidolist"
grupo_html <- html_nodes(pagina_web,css_grupo)
grupo_texto <- html_text(grupo_html)
head(grupo_texto)
dataWS4 <- data.frame(NOMBRE = nombre_texto, GRUPO = grupo_texto)
head(dataWS4)
url="https://www.gob.pe/institucion/mef/funcionarios"
pagina_web=read_html(url)
css_nombre="h3.text-2xl"
nombre_html <- html_nodes(pagina_web,css_nombre)
nombre_texto <- html_text(nombre_html)
css_cargo="p"
cargo_html <- html_nodes(pagina_web,css_cargo)
cargo_texto <- html_text(cargo_html)
dataWS5 <- data.frame(NOMBRE = nombre_texto, CARGO = cargo_texto)
head(dataWS5)
url="https://www.gob.pe/institucion/mef/funcionarios?sheet="
css_cargo="p"
css_name="h3.text-2xl"
final_table = list() # list es una función para crear listas
library(dplyr)
for(i in 1:3) { # INPUT
webpage <- read_html(paste0(url, i)) #obtenemos el código html de las 3 páginas
cargo_texto <- webpage %>%
html_nodes(css_cargo) %>% # obtener el código html del css del cargo
html_text() # lo convertimos en un vector de texto
name_texto <- webpage %>%
html_nodes(css_name) %>% # obtener el código html del css del name
html_text() # lo convertimos en un vector de texto
final_table[[i]] <- data.frame(NOMBRE=name_texto, CARGO=cargo_texto) # OUTPUT: Con esto estamos creando una lista con 3 data frames que contenga las 3 páginas scrapeadas
}
dataWS6 = bind_rows(final_table)
head(dataWS6)
url = "http://search.beaconforfreedom.org/search/censored_publications/result.html?author=&cauthor=&title=&country=7327&language=&censored_year=&censortype=&published_year=&censorreason=&sort=t&page="
path = "/html/body/div/div[2]/div[2]/table"
final_table = list()
for(i in 1:10) {
data <- htmltab((paste0(url, i)),path)
final_table[[i]] <- data.frame(data, stringsAsFactors = F)
}
api_key = "FTIcvj7g6Y1mC5Y1OzEh3JZuJ"
api_secret = "Q2qNZKVW2mFo0uGiAlfu1pUpSPJWJOu7QMHpIXRNVOoTZp2tQ7"
access_token = "226242119-hIEVpAn1WguJucKsZ9Gpm25wLvh8aPUQltUiehf6"
access_token_secret = "pwlLdmZyeE0kDXYiwDNelC82pCksEgTyGruDHUIoHC220"
library(twitteR)
token<- create_token(app = "GRT1APP", api_key, api_secret,access_token, access_token_secret)
api_key <- "35FVibXbAwPZfJrd9hqvQgETt"
api_secret <- "fSm8xWZrKhwnpp6MdpVfqzksOLAPoymFb45bW7W7PuIKamMQoI"
access_token <- "226242119-iMt7C53QNLGK59PfRHA3C8luAEr5BAWmeVuoJQLf"
access_token_secret <- "hm2FWw1URVsGKM9DBgXVxrTQuU8A29A5sSJ2j8pKlxkGJ"
token<- create_token(app = "App2Xzy", api_key, api_secret,access_token, access_token_secret)
cerron <- get_timeline("@MinCulturaPe", 1000)
cerron[1,5]
knitr::opts_chunk$set(echo = TRUE)
library(jsonlite)
#API key = cffa4fb8-7a16-cd85-7946-263722530f15
request = "https://creativecommons.tankerkoenig.de/api/v4/stations/search?apikey=cffa4fb8-7a16-cd85-7946-263722530f15&lat=48.8&lng=9.24&rad=10"
gas = fromJSON(request)
#Tengo que crear el data frame manualmente
data.gas = as.data.frame(gas[["stations"]])
View(data.gas)
library(httr)
library(jsonlite)
headers = c(
'Ocp-Apim-Subscription-Key' = '{6475530489464c529b7bf2a2332a8f5a}'
)
params = list()
# Request parameters
params['locale'] = 'en'
resp <- GET(paste0("https://api.wto.org/qr/v1/non-wto-agreements?"
, paste0(names(params),'=',params,collapse = "&")),
add_headers(headers))
miLLAVE="qSkbCUJKTaiObg6ckWwFHFw3HfSOP34aA2NEw88n"
link="http://api.datosabiertos.oefa.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="PEDID-FISCA"
FORMATO="/data.pjson/"
KEY="?auth_key="
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE)
library(jsonlite)
OEFA = fromJSON(request)
dataOEFA=data.frame(OEFA$result)
miLLAVE = "yiYmrxKojGAvSdPAfOtYWAJlnIAROBBva1OdG8VI"
link="http://api.datosabiertos.munlima.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="UBICA-DE-CAMAR-GSGC-69245"
FORMATO="/data.pjson/"
KEY="?auth_key="
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE)
request
library(jsonlite)
Camaras_Lima = fromJSON(request)
knitr::opts_chunk$set(echo = TRUE)
MYKEY= "RHpLfHbi6oNA33a5vTcgDfeIszfCOpQFENXc2Ju1"
link="http://cne.cloudapi.junar.com"
RQJSON="/api/v2/datastreams/"
GUID="CONSU-DE-COMBU-EN-EL"
FORMATO="/data.json/"
KEY="?auth_key="
request5=paste0(link,RQJSON,GUID,FORMATO,KEY,MYKEY,"&limit=50")
request5
library(jsonlite)
CHILE = fromJSON(request5)
Llave="ygzlrDlGbB52D0APHE8pKtBtnG8MgERwd3ZcyG5E"
request="http://api.datos.agrorural.gob.pe/api/v2/datastreams/INGRE-ECONO-DE-LA-FAMIL/data.json/?auth_key=ygzlrDlGbB52D0APHE8pKtBtnG8MgERwd3ZcyG5E"
request
library(jsonlite)
AGRO = fromJSON(request)
knitr::opts_chunk$set(echo = TRUE)
require("httr")
require("jsonlite")
response <- GET( url = "http://cne.cloudapi.junar.com/api/v2/datastreams/VENTA-ANUAL-NACIO-DE-COMBU/data.ajson/?auth_key=0GSuboLkyfq6Pw89I5xxQAZ7zkaX4HcjSjbrOxh4&limit=50&")
response_text <- content(response,"text")
install.packages(c("httr", "jsonlite","dplyr"))
install.packages(c("httr", "jsonlite", "dplyr"))
library(httr)
library(jsonlite)
library("dplyr")
res <- GET("https://api.datos.gob.mx/v1/condiciones-atmosfericas")
dat <- fromJSON(rawToChar(res$content))
View(dat)
View(res)
data =data.frame(dat$result)
View(data)
miLLAVE="YibOc35hZ3Kg65g0ZbnPQWa0TrX9sr4GPKiqauqY"
link="http://api.datosabiertos.oefa.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="ACTIV-AFA"
FORMATO="/data.json/"
KEY="?auth_key="
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE) # La función paste0 la usamos para concatenar todos los elementos sin separador
request #mirala
library(jsonlite)
OEFA = fromJSON(request)
link="http://api.datosabiertos.oefa.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="FORTA-DE-CAPAC-EN-FISCA"
FORMATO="/data.json/"
KEY="?auth_key="
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE) # La función paste0 la usamos para concatenar todos los elementos sin separador
request #mirala
library(jsonlite)
OEFA = fromJSON(request)
link="http://api.datosabiertos.oefa.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="ACTIV-AFA-36113"
FORMATO="/data.json/"
KEY="?auth_key="
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE) # La función paste0 la usamos para concatenar todos los elementos sin separador
request #mirala
library(jsonlite)
OEFA = fromJSON(request)
str(OEFA)
View(OEFA)
OEFA = fromJSON(rawToChar(request))
OEFA = fromJSON(request)
str(OEFA)
link="http://api.datosabiertos.oefa.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="ACTIV-AFA-36113"
FORMATO="/data.json/"
KEY="?auth_key="
miLLAVE="Tb8cWCER3JfE3DzbFcesiriPnTwURPuuz7NWmvNU"
link="http://api.datosabiertos.oefa.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="ACTIV-AFA-36113"
FORMATO="/data.json/"
KEY="?auth_key="
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE) # La función paste0 la usamos para concatenar todos los elementos sin separador
request #mirala
library(jsonlite)
OEFA = fromJSON(request)
str(OEFA)
View(OEFA)
View(OEFA)
dataOEFA=data.frame(OEFA$result$fArray)
View(dataOEFA)
View(OEFA)
FORMATO='/data.pjson/'
request2=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE)
request2
OEFA = fromJSON(request2)
View(OEFA)
str(OEFA)
dataOEFA=data.frame(OEFA$result)
head(dataOEFA)
knitr::include_graphics("web.png")
library(rvest)
url="https://www.gob.pe/institucion/rree/funcionarios"
pagina_web=read_html(url)
View(pagina_web)
css_nombre="h3.text-2xl" # contenemos la clase CSS en un objeto
nombre_html <- html_nodes(pagina_web,css_nombre) # con html_nodes y html_text, obtenemos el código html que contiene los nombres
nombre_texto <- html_text(nombre_html)
head(nombre_texto) #vemos los datos
css_cargo="p"
cargo_html <- html_nodes(pagina_web,css_cargo)
cargo_texto <- html_text(cargo_html)
head(cargo_texto)
link = "https://en.wikipedia.org/wiki/Democracy_Index"
path = "/html/body/div[3]/div[3]/div[5]/div[1]/table[5]"
nombre_html <- html_nodes(link,path)
nombre_html <- html_nodes(link,table)
nombre_html <- html_nodes(link,table)
nombre_html <- html_nodes(link,"table")
link = "https://en.wikipedia.org/wiki/Democracy_Index"
nombre_html <- html_nodes(link,"table")
link=read_html("https://en.wikipedia.org/wiki/Democracy_Index")
nombre_html <- html_nodes(link,"table")
View(nombre_html)
head(nombre_html)
View(link)
View(nombre_html)
library(rvest)
library(rvest)
codigo_html <- read_html("https://en.wikipedia.org/wiki/Democracy_Index")
tablas <- html_table(codigo_html)
class(tablas)
View(tablas)
tablas[[1]]
tablas[[3]]
codigo_html = read_html("https://en.wikipedia.org/wiki/Democracy_Index")
path = "/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[5]"
url = read_html("https://en.wikipedia.org/wiki/Democracy_Index")
path = "/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[5]"
tablas = html_nodes(url,xpath = path)
View(tablas)
cargo_texto <- html_text(tablas)
library(rvest)
testlink=read_html("https://en.wikipedia.org/wiki/Democracy_Index")
table = testlink%>%
html_nodes(xpath='/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[5]')%>%
html_table()
table
View(table)
table =data.frame(table)
View(table)
url = read_html("https://en.wikipedia.org/wiki/Democracy_Index")
table = html_nodes(url, xpath='/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[5]')
table = html_table (table)
table =data.frame(table)
View(table)
library(rvest)
url = read_html("https://en.wikipedia.org/wiki/Democracy_Index")
table = html_nodes(url, xpath='/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[5]')
table = html_table (table)
table =data.frame(table)
View(table)
library(rvest)
url="https://www.gob.pe/institucion/rree/funcionarios"
pagina_web=read_html(url)
library(rvest)
url="https://www.gob.pe/institucion/rree/funcionarios"
pagina_web=read_html(url)
knitr::include_graphics("web3.png")
css_nombre="h3.text-2xl" # contenemos la clase CSS en un objeto
nombre_html <- html_nodes(pagina_web,css_nombre) # con html_nodes y html_text, obtenemos el código html que contiene los nombres
nombre_texto <- html_text(nombre_html)
head(nombre_texto) #vemos los datos
css_cargo="p"
cargo_html <- html_nodes(pagina_web,css_cargo)
cargo_texto <- html_text(cargo_html)
head(cargo_texto)
dataWS3 <- data.frame(NOMBRE = nombre_texto, CARGO = cargo_texto)
head(dataWS3)
url="https://www.congreso.gob.pe/?K=113"
pagina_web=read_html(url)
View(dataWS3)
url="https://www.congreso.gob.pe/?K=113"
pagina_web=read_html(url)
css_nombre="a.conginfo" # contenemos la clase CSS en un objeto
nombre_html <- html_nodes(pagina_web,css_nombre) # con html_nodes y html_text, obtenemos el código html que contiene los países
nombre_texto <- html_text(nombre_html)
head(nombre_texto) #vemos los datos
css_grupo="span.partidolist"
grupo_html <- html_nodes(pagina_web,css_grupo)
grupo_texto <- html_text(grupo_html)
head(grupo_texto)
dataWS4 <- data.frame(NOMBRE = nombre_texto, GRUPO = grupo_texto)
head(dataWS4)
View(dataWS4)
url="https://www.gob.pe/institucion/mef/funcionarios"
pagina_web=read_html(url)
css_nombre="h3.text-2xl"
nombre_html <- html_nodes(pagina_web,css_nombre)
nombre_texto <- html_text(nombre_html)
css_cargo="p"
cargo_html <- html_nodes(pagina_web,css_cargo)
cargo_texto <- html_text(cargo_html)
dataWS5 <- data.frame(NOMBRE = nombre_texto, CARGO = cargo_texto)
head(dataWS5)
url="https://www.gob.pe/institucion/mef/funcionarios?sheet="
css_cargo="p"
css_name="h3.text-2xl"
final_table = list() # list es una función para crear listas
library(dplyr)
for(i in 1:3) { # INPUT
webpage <- read_html(paste0(url, i)) #obtenemos el código html de las 3 páginas
cargo_texto <- webpage %>%
html_nodes(css_cargo) %>% # obtener el código html del css del cargo
html_text() # lo convertimos en un vector de texto
name_texto <- webpage %>%
html_nodes(css_name) %>% # obtener el código html del css del name
html_text() # lo convertimos en un vector de texto
final_table[[i]] <- data.frame(NOMBRE=name_texto, CARGO=cargo_texto) # OUTPUT: Con esto estamos creando una lista con 3 data frames que contenga las 3 páginas scrapeadas
}
dataWS6 = bind_rows(final_table)
head(dataWS6)
knitr::include_graphics("web3.png")
